HOST='0.0.0.0'
PORT=3000

# MODEL RELATED
USE_LOCAL=false         # Set to true if you want to use a local model
MODEL='DEFAULT'         # Be sure to use the correct model name - Set USE_LOCAL accordingly

## REMOTE - OpenAI
OPENAI_API_KEY='<your-openai-api-key>'

## LOCAL - Ollama
OLLAMA_HOST='http://0.0.0.0'
OLLAMA_PORT=11434

# LANGCHAIN TRACING
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_API_KEY="<your-api-key-here>"
LANGCHAIN_PROJECT="<your-project-name-here>"